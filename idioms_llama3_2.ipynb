{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaw3wHyVDXx3KZjTYhTWlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eddiechu888/idioms/blob/main/idioms_llama3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1d_E_IitJHMc",
        "outputId": "bb1cbb41-9987-463b-93d6-8e28f0957f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Hugging Face token: ··········\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hooks registered on model layers.\n",
            "\n",
            "Processing 'idiomatic' sentence:\n",
            "Sentence: She thought of good ways to break the ice at the company retreat.\n",
            "Hook 'layer_0': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_1': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_2': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_3': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_4': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_5': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_6': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_7': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_8': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_9': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_10': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_11': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_12': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_13': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_14': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_15': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Activations captured for 'idiomatic' condition.\n",
            "\n",
            "Processing 'non_idiomatic' sentence:\n",
            "Sentence: She thought of good ways to get people talking at the company retreat.\n",
            "Hook 'layer_0': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_1': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_2': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_3': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_4': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_5': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_6': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_7': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_8': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_9': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_10': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_11': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_12': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_13': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_14': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Hook 'layer_15': Capturing Tensor with shape torch.Size([1, 15, 2048])\n",
            "Activations captured for 'non_idiomatic' condition.\n",
            "\n",
            "Processing 'literal' sentence:\n",
            "Sentence: She thought of good ways to break the ice to make a cold drink.\n",
            "Hook 'layer_0': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_1': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_2': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_3': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_4': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_5': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_6': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_7': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_8': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_9': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_10': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_11': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_12': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_13': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_14': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Hook 'layer_15': Capturing Tensor with shape torch.Size([1, 16, 2048])\n",
            "Activations captured for 'literal' condition.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (15) must match the size of tensor b (16) at non-singleton dimension 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ebc9d417c7a1>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;31m# Compute differences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mdifference_idiom_non_idiom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midiom_avg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnon_idiom_avg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mdifference_idiom_literal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midiom_avg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mliteral_avg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nAverage activation difference for {layer_to_compare} (Idiomatic - Non-Idiomatic): {difference_idiom_non_idiom}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (15) must match the size of tensor b (16) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from getpass import getpass\n",
        "\n",
        "# 1. Setup\n",
        "hf_token = getpass('Enter your Hugging Face token: ')\n",
        "\n",
        "if hf_token is None:\n",
        "    raise ValueError(\"HUGGINGFACE_TOKEN is not set.\")\n",
        "\n",
        "model_name = 'meta-llama/Llama-3.2-1B'\n",
        "\n",
        "# Check for CUDA and MPS availability and use the best available option\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize tokenizer and model with the HF token for authentication\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token).to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# 2. Define the Single Data Example\n",
        "single_example = {\n",
        "    \"idiomatic\": \"She thought of good ways to break the ice at the company retreat.\",\n",
        "    \"non_idiomatic\": \"She thought of good ways to get people talking at the company retreat.\",\n",
        "    \"literal\": \"She thought of good ways to break the ice to make a cold drink.\"\n",
        "}\n",
        "\n",
        "# 3. Define Hook for Activations\n",
        "activations = defaultdict(list)\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        # If output is a tuple, extract the first element (hidden states)\n",
        "        if isinstance(output, tuple):\n",
        "            output = output[0]\n",
        "\n",
        "        # If output is a list, extract the first element\n",
        "        if isinstance(output, list):\n",
        "            output = output[0]\n",
        "\n",
        "        # Check if the output is a Tensor\n",
        "        if isinstance(output, torch.Tensor):\n",
        "            print(f\"Hook '{name}': Capturing Tensor with shape {output.shape}\")\n",
        "            activations[name].append(output.detach().cpu())\n",
        "        else:\n",
        "            print(f\"Hook '{name}': Output is of type {type(output)}, skipping.\")\n",
        "    return hook\n",
        "\n",
        "# Register hooks on desired layers\n",
        "# It's crucial to inspect the model architecture to correctly access the transformer layers.\n",
        "# For LLaMA models, the transformer layers are typically under model.model.layers\n",
        "# Adjust the attribute path if necessary.\n",
        "\n",
        "for i, layer in enumerate(model.model.layers):\n",
        "    layer_name = f'layer_{i}'\n",
        "    layer.register_forward_hook(get_activation(layer_name))\n",
        "\n",
        "print(\"Hooks registered on model layers.\")\n",
        "\n",
        "# 4. Function to Process a Sentence and Capture Activations\n",
        "def process_sentence(sentence, max_length=20):\n",
        "    encoded_input = tokenizer(\n",
        "        sentence,\n",
        "        return_tensors='pt',\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    ).to(device)\n",
        "    with torch.no_grad():\n",
        "        model(**encoded_input)\n",
        "    # After forward pass, activations are populated via hooks\n",
        "    return\n",
        "\n",
        "# 5. Process Each Sentence in the Triplet\n",
        "conditions = ['idiomatic', 'non_idiomatic', 'literal']\n",
        "condition_activations = {condition: defaultdict(list) for condition in conditions}\n",
        "\n",
        "for condition in conditions:\n",
        "    sentence = single_example[condition]\n",
        "    print(f\"\\nProcessing '{condition}' sentence:\")\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "\n",
        "    # Clear previous activations\n",
        "    activations.clear()\n",
        "\n",
        "    # Process the sentence\n",
        "    process_sentence(sentence)\n",
        "\n",
        "    # Store activations\n",
        "    for layer, act in activations.items():\n",
        "        condition_activations[condition][layer].extend(act)\n",
        "\n",
        "    print(f\"Activations captured for '{condition}' condition.\")\n",
        "\n",
        "# 6. Analyze and Compare Activations\n",
        "# For simplicity, we'll compute the average activation for each layer and visualize differences.\n",
        "\n",
        "def compute_average_activation(activations_dict):\n",
        "    average_activation = {}\n",
        "    for layer, acts in activations_dict.items():\n",
        "        # Stack all activations for the layer (should be only one in this case)\n",
        "        stacked = torch.cat(acts, dim=0)  # Shape: [batch_size, ...]\n",
        "        # Compute the mean across the batch dimension\n",
        "        average = stacked.mean(dim=0)\n",
        "        average_activation[layer] = average\n",
        "    return average_activation\n",
        "\n",
        "avg_idiomatic = compute_average_activation(condition_activations['idiomatic'])\n",
        "avg_non_idiomatic = compute_average_activation(condition_activations['non_idiomatic'])\n",
        "avg_literal = compute_average_activation(condition_activations['literal'])\n",
        "\n",
        "# Example: Compare average activations of a specific layer\n",
        "layer_to_compare = 'layer_0'  # Change as needed\n",
        "\n",
        "idiom_avg = avg_idiomatic[layer_to_compare]\n",
        "non_idiom_avg = avg_non_idiomatic[layer_to_compare]\n",
        "literal_avg = avg_literal[layer_to_compare]\n",
        "\n",
        "# Compute differences\n",
        "difference_idiom_non_idiom = idiom_avg - non_idiom_avg\n",
        "difference_idiom_literal = idiom_avg - literal_avg\n",
        "\n",
        "print(f\"\\nAverage activation difference for {layer_to_compare} (Idiomatic - Non-Idiomatic): {difference_idiom_non_idiom}\")\n",
        "print(f\"Average activation difference for {layer_to_compare} (Idiomatic - Literal): {difference_idiom_literal}\")\n",
        "\n",
        "# 7. Visualize Activation Differences\n",
        "# We'll plot the activation differences as heatmaps.\n",
        "\n",
        "def plot_activation_difference(difference_tensor, layer_name, condition_pair):\n",
        "    difference_np = difference_tensor.numpy()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(difference_np, cmap='coolwarm')\n",
        "    plt.title(f'Activation Differences in {layer_name} ({condition_pair})')\n",
        "    plt.xlabel('Neuron Index')\n",
        "    plt.ylabel('Hidden Units' if len(difference_np.shape) > 1 else 'Dimension')\n",
        "    plt.show()\n",
        "\n",
        "# Plotting the differences\n",
        "plot_activation_difference(difference_idiom_non_idiom, layer_to_compare, 'Idiomatic - Non-Idiomatic')\n",
        "plot_activation_difference(difference_idiom_literal, layer_to_compare, 'Idiomatic - Literal')"
      ]
    }
  ]
}